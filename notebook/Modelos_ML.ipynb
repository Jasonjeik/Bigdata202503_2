{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64da2a1ab8024012b61b4ac1f353a563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffe123b17bd64c6782a286e70eed1a2f",
              "IPY_MODEL_ede0bf2d2a7f49a0a8e047df89df426a",
              "IPY_MODEL_0aac520145f249cbb4fd5b868109c48a"
            ],
            "layout": "IPY_MODEL_600ca84cd8504f2096e01b97fde462c2"
          }
        },
        "ffe123b17bd64c6782a286e70eed1a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_614badf215a14ee59ac3eed947948cee",
            "placeholder": "​",
            "style": "IPY_MODEL_a5fe5dc0cb2945d7bc26b83cf5c16749",
            "value": "Map: 100%"
          }
        },
        "ede0bf2d2a7f49a0a8e047df89df426a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c31c7c5d7249f0a8392e145862a43f",
            "max": 30000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5eea370ac0dd42e195893d6baa342faf",
            "value": 30000
          }
        },
        "0aac520145f249cbb4fd5b868109c48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8abcdeacecc4673bb3ac3572dde6e19",
            "placeholder": "​",
            "style": "IPY_MODEL_24f8baabae4645f4b6f8624b7fd7b862",
            "value": " 30000/30000 [00:07&lt;00:00, 4186.28 examples/s]"
          }
        },
        "600ca84cd8504f2096e01b97fde462c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "614badf215a14ee59ac3eed947948cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5fe5dc0cb2945d7bc26b83cf5c16749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9c31c7c5d7249f0a8392e145862a43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eea370ac0dd42e195893d6baa342faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8abcdeacecc4673bb3ac3572dde6e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f8baabae4645f4b6f8624b7fd7b862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "900cb47e88f24d6db59e1495e4a6f7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e7e55b49fec44bb8450e49d1ebb7e93",
              "IPY_MODEL_929f85afb29c498e9e9f9416695ca7db",
              "IPY_MODEL_41a7c1fbe54d4e5fa1a2055f00965b83"
            ],
            "layout": "IPY_MODEL_01c41ced3d6f4a438b10bd4279172725"
          }
        },
        "8e7e55b49fec44bb8450e49d1ebb7e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67cde80980674f62b735fb09711b5dc0",
            "placeholder": "​",
            "style": "IPY_MODEL_c47f20e7f7044f16bce2501384034d6f",
            "value": "Map: 100%"
          }
        },
        "929f85afb29c498e9e9f9416695ca7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f57bb914ef4af4a4a7807b8d0b9a26",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af096f09a5e43dbb3174fe88444f150",
            "value": 10000
          }
        },
        "41a7c1fbe54d4e5fa1a2055f00965b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d0f80b387e441ab9cd18e195fe2925",
            "placeholder": "​",
            "style": "IPY_MODEL_b1edaa8d37264a7ba7c774e4fea8f313",
            "value": " 10000/10000 [00:02&lt;00:00, 4195.58 examples/s]"
          }
        },
        "01c41ced3d6f4a438b10bd4279172725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67cde80980674f62b735fb09711b5dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47f20e7f7044f16bce2501384034d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f57bb914ef4af4a4a7807b8d0b9a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af096f09a5e43dbb3174fe88444f150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0d0f80b387e441ab9cd18e195fe2925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1edaa8d37264a7ba7c774e4fea8f313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook Entranamiento Modelos con GPU**\n",
        "\n",
        "Correr usando GPU A100 de colab unicamente.\n"
      ],
      "metadata": {
        "id": "bruY5USQtJRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 0\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# 1. Definir la ruta base en tu Google Drive\n",
        "base_path = '/content/drive/MyDrive/Proyecto 2'\n",
        "\n",
        "# 2. Crear toda la estructura de carpetas (una sola vez)\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "os.makedirs(f\"{base_path}/api/models\", exist_ok=True)\n",
        "os.makedirs(f\"{base_path}/dashboard\", exist_ok=True)\n",
        "os.makedirs(f\"{base_path}/scripts\", exist_ok=True)\n",
        "os.makedirs(f\"{base_path}/data\", exist_ok=True)\n",
        "os.makedirs(\"api/models/history_plots\", exist_ok=True)\n",
        "\n",
        "# 3. Eliminar cualquier enlace simbólico viejo (por si acaso)\n",
        "if os.path.exists('/content/Proyecto 2'):\n",
        "    !rm -rf '/content/Proyecto 2'\n",
        "\n",
        "# 4. Crear el enlace simbólico correcto (¡una sola vez!)\n",
        "os.symlink(base_path, '/content/Proyecto 2', target_is_directory=True)\n",
        "\n",
        "# 5. Cambiar al directorio del proyecto\n",
        "%cd /content/Proyecto 2\n",
        "\n",
        "# 6. Verificar que todo quedó perfecto\n",
        "print(\"¡Estructura replicada correctamente!\")\n",
        "!pwd\n",
        "!ls -la\n",
        "!ls -la api/models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPh_t-4DAdHt",
        "outputId": "ed66b10f-536b-48ff-81fb-7acbe062a3ef"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Proyecto 2\n",
            "¡Estructura replicada correctamente!\n",
            "/content/drive/MyDrive/Proyecto 2\n",
            "total 20\n",
            "drwx------ 3 root root 4096 Nov 21 01:34 api\n",
            "drwx------ 2 root root 4096 Nov 21 01:34 dashboard\n",
            "drwx------ 4 root root 4096 Nov 21 01:35 data\n",
            "drwx------ 2 root root 4096 Nov 21 01:03 .ipynb_checkpoints\n",
            "drwx------ 2 root root 4096 Nov 21 01:34 scripts\n",
            "total 303157\n",
            "drwx------ 2 root root      4096 Nov 21 04:28 distilbert_final\n",
            "drwx------ 4 root root      4096 Nov 21 04:28 distilbert_finetuned\n",
            "drwx------ 2 root root      4096 Nov 21 04:14 history_plots\n",
            "-rw------- 1 root root    930772 Nov 21 01:51 logistic_regression_tfidf.pkl\n",
            "-rw------- 1 root root        78 Nov 21 01:51 lr_best_params.pkl\n",
            "-rw------- 1 root root  22879253 Nov 21 02:59 lstm_anti_overfit_final.pth\n",
            "-rw------- 1 root root  22878825 Nov 21 02:59 lstm_best_ever.pth\n",
            "-rw------- 1 root root       110 Nov 21 04:07 lstm_best_params.pkl\n",
            "-rw------- 1 root root       169 Nov 21 04:14 lstm_cv_history.json\n",
            "-rw------- 1 root root    326991 Nov 21 03:11 lstm_final_curves.png\n",
            "-rw------- 1 root root  33846751 Nov 21 04:14 lstm_final_cv_complete.pth\n",
            "-rw------- 1 root root  27049561 Nov 21 03:25 lstm_final_optuna.pth\n",
            "-rw------- 1 root root  27048695 Nov 21 02:45 lstm_final.pth\n",
            "-rw------- 1 root root      1183 Nov 21 02:46 lstm_history_detailed.json\n",
            "-rw------- 1 root root    273155 Nov 21 03:25 lstm_training_history.png\n",
            "-rw------- 1 root root  22878977 Nov 21 03:11 lstm_turbo_final.pth\n",
            "-rw------- 1 root root 151905013 Nov 21 01:54 random_forest.pkl\n",
            "-rw------- 1 root root        80 Nov 21 01:55 rf_best_params.pkl\n",
            "-rw------- 1 root root    396149 Nov 21 04:14 vocab_lstm.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nxUVvEaclfQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93e1d66-ff0e-45e3-d80d-14acca4bd351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# CELDA 1 - Instalar todo (solo una vez)\n",
        "!pip install -q scikit-learn pandas numpy torch torchvision torchtext tqdm matplotlib seaborn transformers datasets evaluate joblib pymongo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARREGLAR SSL EN COLAB PARA MONGODB ATLAS (2025)\n",
        "!pip install --upgrade certifi pymongo dnspython\n",
        "import certifi\n",
        "import ssl\n",
        "import os\n",
        "\n",
        "# Forzar certificados actualizados\n",
        "os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()\n",
        "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
        "\n",
        "print(\"Certificados actualizados para MongoDB Atlas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3efh_aW0W7N",
        "outputId": "071fc98e-9202-43be-8527-3b71dc1d5875"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (2025.11.12)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.15.4)\n",
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.12/dist-packages (2.8.0)\n",
            "Certificados actualizados para MongoDB Atlas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 2 - CARGAR DATOS DESDE MONGODB ATLAS (100% COMPATIBLE CON TU PROYECTO)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from pymongo import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "import urllib.parse\n",
        "\n",
        "# === CONEXIÓN (ya funciona) ===\n",
        "user = urllib.parse.quote_plus(\"jasonebm16_db_user\")\n",
        "pw   = urllib.parse.quote_plus(\"JK0jknwzzkJdRaDt\")\n",
        "uri = f\"mongodb+srv://{user}:{pw}@bdproyecto2.u5gbblq.mongodb.net/?retryWrites=true&w=majority&appName=BDProyecto2\"\n",
        "\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "client.admin.command('ping')\n",
        "print(\"¡CONECTADO A MONGODB ATLAS!\")\n",
        "\n",
        "# === CARGAR DATOS ===\n",
        "db = client[\"imdb_dataset\"]\n",
        "collection = db[\"reviews\"]\n",
        "\n",
        "print(\"Cargando 50,000 reseñas desde tu cluster online...\")\n",
        "raw_df = pd.DataFrame(list(collection.find({}, {\"_id\": 0})))\n",
        "\n",
        "print(f\"Documentos crudos cargados: {len(raw_df):,}\")\n",
        "\n",
        "# === ADAPTAR ESTRUCTURA PARA QUE COINCIDA CON TU CÓDIGO ANTERIOR ===\n",
        "# Tus documentos tienen:  'text' (str) y 'label' (1 o 0)\n",
        "# Tu código espera:       'text' (str) y 'sentiment' (1 o 0)\n",
        "\n",
        "df = raw_df.copy()\n",
        "df = df.rename(columns={'label': 'sentiment'})  # ← CLAVE: ahora existe 'sentiment'\n",
        "\n",
        "# Limpieza final (por si acaso)\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub('<.*?>', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "df = df[df['text'].str.len() > 10].reset_index(drop=True)\n",
        "\n",
        "# === DIVISIÓN EXACTAMENTE IGUAL QUE ANTES ===\n",
        "train_df, temp = train_test_split(\n",
        "    df, test_size=0.4, random_state=42, stratify=df['sentiment']\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp, test_size=0.5, random_state=42, stratify=temp['sentiment']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df):,} | Val: {len(val_df):,} | Test: {len(test_df):,}\")\n",
        "print(\"¡DATOS 100% COMPATIBLES CON TODAS TUS CELDAS ANTERIORES!\")\n",
        "print(\"Columnas disponibles:\", df.columns.tolist())\n",
        "print(\"Ejemplo:\")\n",
        "print(f\"Texto: {train_df.iloc[0]['text'][:100]}...\")\n",
        "print(f\"Sentimiento: {'Positivo' if train_df.iloc[0]['sentiment'] == 1 else 'Negativo'}\")\n",
        "\n",
        "client.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3QnPhQ_6DxD",
        "outputId": "ec7f5d1f-4e80-4160-84c4-c19e086f32bb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡CONECTADO A MONGODB ATLAS!\n",
            "Cargando 50,000 reseñas desde tu cluster online...\n",
            "Documentos crudos cargados: 50,000\n",
            "Train: 30,000 | Val: 10,000 | Test: 10,000\n",
            "¡DATOS 100% COMPATIBLES CON TODAS TUS CELDAS ANTERIORES!\n",
            "Columnas disponibles: ['text', 'sentiment']\n",
            "Ejemplo:\n",
            "Texto: it looked cool from the movie sleeve but after five minutes we werent sure if it was a homosexual do...\n",
            "Sentimiento: Negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 3 - Modelo 1: Logistic Regression + TF-IDF con GridSearch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pipe_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "param_grid_lr = {\n",
        "    'tfidf__max_features': [10000, 20000],\n",
        "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
        "    'lr__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(pipe_lr, param_grid_lr, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_lr.fit(train_df['text'], train_df['sentiment'])\n",
        "\n",
        "print(f\"Best LR Accuracy: {grid_lr.best_score_:.4f}\")\n",
        "print(f\"Best params: {grid_lr.best_params_}\")\n",
        "\n",
        "# EXPORTAR\n",
        "joblib.dump(grid_lr.best_estimator_, \"api/models/logistic_regression_tfidf.pkl\")\n",
        "joblib.dump(grid_lr.best_params_, \"api/models/lr_best_params.pkl\")\n",
        "print(\"Logistic Regression exportado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzxe72VW6JlB",
        "outputId": "26d37c6d-8bf4-4457-849a-3c0e815109f7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Best LR Accuracy: 0.8840\n",
            "Best params: {'lr__C': 10, 'tfidf__max_features': 20000, 'tfidf__ngram_range': (1, 2)}\n",
            "Logistic Regression exportado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 4 - Modelo 2: Random Forest con GridSearch\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe_rf = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=20000, ngram_range=(1,2))),\n",
        "    ('rf', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "param_grid_rf = {\n",
        "    'rf__n_estimators': [100, 200],\n",
        "    'rf__max_depth': [20, None],\n",
        "    'rf__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(pipe_rf, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_rf.fit(train_df['text'], train_df['sentiment'])\n",
        "\n",
        "print(f\"Best RF Accuracy: {grid_rf.best_score_:.4f}\")\n",
        "print(f\"Best params: {grid_rf.best_params_}\")\n",
        "\n",
        "# EXPORTAR\n",
        "joblib.dump(grid_rf.best_estimator_, \"api/models/random_forest.pkl\")\n",
        "joblib.dump(grid_rf.best_params_, \"api/models/rf_best_params.pkl\")\n",
        "print(\"Random Forest exportado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sVQhwl57LHN",
        "outputId": "64abd898-3ddc-4dcb-9bdb-5afdd7dd2154"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best RF Accuracy: 0.8512\n",
            "Best params: {'rf__max_depth': None, 'rf__min_samples_split': 5, 'rf__n_estimators': 200}\n",
            "Random Forest exportado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA MEJORES PARÁMETROS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import optuna\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# ====================== 1. Vocabulario y Dataset ======================\n",
        "def clean_and_tokenize(text):\n",
        "    text = re.sub(r'<.*?>', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "    return text.lower().split()\n",
        "\n",
        "all_tokens = [t for text in train_df['text'] for t in clean_and_tokenize(text)]\n",
        "vocab = {'<pad>': 0, '<unk>': 1}\n",
        "vocab.update({w: i+2 for i, (w, _) in enumerate(Counter(all_tokens).most_common(30000))})\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulario: {vocab_size:,} tokens\")\n",
        "\n",
        "MAX_LEN = 200\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts.reset_index(drop=True)\n",
        "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i):\n",
        "        tokens = clean_and_tokenize(self.texts.iloc[i])[:MAX_LEN]\n",
        "        seq = [vocab.get(t, vocab['<unk>']) for t in tokens]\n",
        "        seq += [vocab['<pad>']] * (MAX_LEN - len(seq))\n",
        "        return torch.tensor(seq), self.labels[i]\n",
        "\n",
        "train_ds = SentimentDataset(train_df['text'], train_df['sentiment'])\n",
        "val_ds   = SentimentDataset(val_df['text'],   val_df['sentiment'])\n",
        "\n",
        "# ====================== RESUMEN MANUAL CORREGIDO (sin errores) ======================\n",
        "def model_summary(model):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESUMEN DEL MODELO LSTM\")\n",
        "    print(\"=\"*70)\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total parámetros: {total:,}\")\n",
        "    print(f\"Entrenables: {trainable:,}\")\n",
        "    print(f\"No entrenables: {total - trainable:,}\\n\")\n",
        "\n",
        "    x = torch.randint(0, 100, (1, MAX_LEN)).to(device)  # batch 1\n",
        "    with torch.no_grad():\n",
        "        print(f\"Input → {x.shape} (torch.int64)\")\n",
        "        x = model.embedding(x).float()  # ← Aquí convertimos a float\n",
        "        print(f\"Embedding → {x.shape}\")\n",
        "        lstm_out, (h_n, c_n) = model.lstm(x)\n",
        "        print(f\"LSTM output → {lstm_out.shape}\")\n",
        "        print(f\"LSTM hidden → {h_n.shape} (último hidden state)\")\n",
        "        if model.lstm.bidirectional:\n",
        "            h = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
        "        else:\n",
        "            h = h_n[-1]\n",
        "        print(f\"Hidden concatenado → {h.shape}\")\n",
        "        x = model.dropout(h)\n",
        "        x = model.relu(model.fc1(x))\n",
        "        print(f\"FC1 + ReLU → {x.shape}\")\n",
        "        x = model.dropout(x)\n",
        "        x = model.relu(model.fc2(x))\n",
        "        print(f\"FC2 + ReLU → {x.shape}\")\n",
        "        logits = model.output(x)\n",
        "        print(f\"Output (logits) → {logits.shape} → 2 clases (neg/pos)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# ====================== Modelo + Optuna ======================\n",
        "def create_model(trial):\n",
        "    embed_dim     = trial.suggest_int('embed_dim', 96, 256, step=32)\n",
        "    hidden_dim    = trial.suggest_int('hidden_dim', 128, 512, step=64)\n",
        "    num_layers    = trial.suggest_int('num_layers', 1, 3)\n",
        "    dropout       = trial.suggest_float('dropout', 0.3, 0.6)\n",
        "    bidirectional = trial.suggest_categorical('bidirectional', [True, False])\n",
        "\n",
        "    class LSTMOptuna(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "            self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers,\n",
        "                                batch_first=True, dropout=dropout if num_layers>1 else 0,\n",
        "                                bidirectional=bidirectional)\n",
        "            lstm_out = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "            self.fc1 = nn.Linear(lstm_out, 128)\n",
        "            self.fc2 = nn.Linear(128, 64)\n",
        "            self.output = nn.Linear(64, 2)\n",
        "            self.relu = nn.ReLU()\n",
        "        def forward(self, x):\n",
        "            x = self.embedding(x)\n",
        "            lstm_out, (h_n, _) = self.lstm(x)\n",
        "            h = torch.cat((h_n[-2], h_n[-1]), dim=1) if self.lstm.bidirectional else h_n[-1]\n",
        "            x = self.dropout(h)\n",
        "            x = self.relu(self.fc1(x))\n",
        "            x = self.dropout(x)\n",
        "            x = self.relu(self.fc2(x))\n",
        "            return self.output(x)\n",
        "\n",
        "    model = LSTMOptuna().to(device)\n",
        "    if trial.number == 0:\n",
        "        model_summary(model)\n",
        "    return model\n",
        "\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    lr = trial.suggest_float('lr', 5e-4, 5e-3, log=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, drop_last=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=128)\n",
        "\n",
        "    best = 0\n",
        "    patience = 2\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(12):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validación\n",
        "        model.eval()\n",
        "        correct = sum(model(x.to(device)).argmax(1).eq(y.to(device)).sum().item()\n",
        "                     for x, y in val_loader)\n",
        "        acc = correct / len(val_df)\n",
        "\n",
        "        trial.report(acc, epoch)\n",
        "        if trial.should_prune(): raise optuna.TrialPruned()\n",
        "        if acc > best:\n",
        "            best = acc\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience: break\n",
        "    return best\n",
        "\n",
        "# ====================== EJECUTAR ======================\n",
        "print(\"\\nINICIANDO OPTUNA (10 trials) – Esto va a volar con tu A100\")\n",
        "study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(f\"\\nMEJOR RESULTADO: {study.best_value:.4f}\")\n",
        "print(\"Mejores hiperparámetros:\", study.best_params)\n",
        "\n",
        "# Guardar el mejor trial para después\n",
        "best_params = study.best_params\n",
        "print(\"¡Listo! Ahora solo falta el entrenamiento final con early stopping – dime “FINAL” y te lo paso en 10 segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSqPPQnnB54W",
        "outputId": "81c52c86-a0ad-443a-c6a8-d8e3dc6394ef"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A100-SXM4-80GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-21 06:27:00,305] A new study created in memory with name: no-name-c4beea81-5c6c-4faf-ad92-f95ca1f9a1c0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 30,002 tokens\n",
            "\n",
            "INICIANDO OPTUNA (10 trials) – Esto va a volar con tu A100\n",
            "\n",
            "======================================================================\n",
            "RESUMEN DEL MODELO LSTM\n",
            "======================================================================\n",
            "Total parámetros: 7,298,754\n",
            "Entrenables: 7,298,754\n",
            "No entrenables: 0\n",
            "\n",
            "Input → torch.Size([1, 200]) (torch.int64)\n",
            "Embedding → torch.Size([1, 200, 192])\n",
            "LSTM output → torch.Size([1, 200, 384])\n",
            "LSTM hidden → torch.Size([4, 1, 192]) (último hidden state)\n",
            "Hidden concatenado → torch.Size([1, 384])\n",
            "FC1 + ReLU → torch.Size([1, 128])\n",
            "FC2 + ReLU → torch.Size([1, 64])\n",
            "Output (logits) → torch.Size([1, 2]) → 2 clases (neg/pos)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-21 06:28:41,727] Trial 0 finished with value: 0.8723 and parameters: {'embed_dim': 192, 'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.49314208391037206, 'bidirectional': True, 'lr': 0.003026795252258237}. Best is trial 0 with value: 0.8723.\n",
            "[I 2025-11-21 06:29:47,180] Trial 1 finished with value: 0.5216 and parameters: {'embed_dim': 160, 'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.5788613386603974, 'bidirectional': False, 'lr': 0.002969257224909509}. Best is trial 0 with value: 0.8723.\n",
            "[I 2025-11-21 06:30:25,903] Trial 2 finished with value: 0.5 and parameters: {'embed_dim': 224, 'hidden_dim': 192, 'num_layers': 3, 'dropout': 0.3669829374749849, 'bidirectional': False, 'lr': 0.004108134230342261}. Best is trial 0 with value: 0.8723.\n",
            "[I 2025-11-21 06:30:54,328] Trial 3 finished with value: 0.5 and parameters: {'embed_dim': 192, 'hidden_dim': 448, 'num_layers': 2, 'dropout': 0.4684947201692462, 'bidirectional': False, 'lr': 0.0008006253444178482}. Best is trial 0 with value: 0.8723.\n",
            "[I 2025-11-21 06:31:35,506] Trial 4 finished with value: 0.8738 and parameters: {'embed_dim': 224, 'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.41228537544637867, 'bidirectional': True, 'lr': 0.002026341759507297}. Best is trial 4 with value: 0.8738.\n",
            "[I 2025-11-21 06:32:23,230] Trial 5 finished with value: 0.5 and parameters: {'embed_dim': 128, 'hidden_dim': 384, 'num_layers': 3, 'dropout': 0.35643450677776334, 'bidirectional': True, 'lr': 0.0014868676726744001}. Best is trial 4 with value: 0.8738.\n",
            "[I 2025-11-21 06:33:01,608] Trial 6 finished with value: 0.5 and parameters: {'embed_dim': 160, 'hidden_dim': 192, 'num_layers': 3, 'dropout': 0.5064421974366795, 'bidirectional': False, 'lr': 0.004286835604001799}. Best is trial 4 with value: 0.8738.\n",
            "[I 2025-11-21 06:33:24,947] Trial 7 finished with value: 0.5016 and parameters: {'embed_dim': 160, 'hidden_dim': 384, 'num_layers': 1, 'dropout': 0.519888756468101, 'bidirectional': False, 'lr': 0.003812919770312583}. Best is trial 4 with value: 0.8738.\n",
            "[I 2025-11-21 06:33:50,823] Trial 8 pruned. \n",
            "[I 2025-11-21 06:34:19,067] Trial 9 finished with value: 0.5035 and parameters: {'embed_dim': 224, 'hidden_dim': 448, 'num_layers': 2, 'dropout': 0.5045630538653634, 'bidirectional': False, 'lr': 0.0033786035674466287}. Best is trial 4 with value: 0.8738.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MEJOR RESULTADO: 0.8738\n",
            "Mejores hiperparámetros: {'embed_dim': 224, 'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.41228537544637867, 'bidirectional': True, 'lr': 0.002026341759507297}\n",
            "¡Listo! Ahora solo falta el entrenamiento final con early stopping – dime “FINAL” y te lo paso en 10 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best_params, \"api/models/lstm_best_params.pkl\")\n",
        "print(\"LSTM Best Parameters exportados\")\n",
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz3N2WxHtChi",
        "outputId": "5a3e1d62-a249-405e-d7c3-389bbbe4e105"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Best Parameters exportados\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'embed_dim': 224,\n",
              " 'hidden_dim': 128,\n",
              " 'num_layers': 2,\n",
              " 'dropout': 0.41228537544637867,\n",
              " 'bidirectional': True,\n",
              " 'lr': 0.002026341759507297}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTRENAMIENTO FINAL DEFINITIVO: 5-FOLD CV + GRÁFICAS + HISTORIAL COMPLETO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Hiperparámetros óptimos de Optuna\n",
        "best_params.update({\n",
        "    'batch_size': 2048,\n",
        "    'weight_decay': 1e-4,\n",
        "    'patience': 6,\n",
        "    'max_epochs': 50\n",
        "})\n",
        "\n",
        "\n",
        "# Dataset\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts.reset_index(drop=True)\n",
        "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = clean_and_tokenize(self.texts.iloc[idx])[:200]\n",
        "        seq = [vocab.get(t, vocab['<unk>']) for t in tokens]\n",
        "        seq += [vocab['<pad>']] * (200 - len(seq))\n",
        "        return torch.tensor(seq), self.labels[idx]\n",
        "\n",
        "# Modelo LSTM\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, best_params['embed_dim'], padding_idx=0)\n",
        "        self.lstm = nn.LSTM(best_params['embed_dim'], best_params['hidden_dim'],\n",
        "                            num_layers=best_params['num_layers'], batch_first=True,\n",
        "                            dropout=0.0, bidirectional=best_params['bidirectional'])\n",
        "        self.dropout = nn.Dropout(best_params['dropout'])\n",
        "        lstm_out = best_params['hidden_dim'] * 2\n",
        "        self.fc1 = nn.Linear(lstm_out, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.output = nn.Linear(64, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        h = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
        "        x = self.dropout(h)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return self.output(x)\n",
        "\n",
        "# Datos completos\n",
        "texts = pd.concat([train_df['text'], val_df['text']]).reset_index(drop=True)\n",
        "labels = pd.concat([train_df['sentiment'], val_df['sentiment']]).reset_index(drop=True)\n",
        "\n",
        "# 5-Fold CV\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_histories = []\n",
        "fold_val_accs = []\n",
        "best_models = []\n",
        "\n",
        "print(\"INICIANDO 5-FOLD CROSS-VALIDATION CON REGISTRO COMPLETO\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels)):\n",
        "    print(f\"{'='*20} FOLD {fold+1}/5 {'='*20}\")\n",
        "\n",
        "    train_texts, val_texts = texts.iloc[train_idx], texts.iloc[val_idx]\n",
        "    train_labels, val_labels = labels.iloc[train_idx], labels.iloc[val_idx]\n",
        "\n",
        "    train_ds = SentimentDataset(train_texts, train_labels)\n",
        "    val_ds   = SentimentDataset(val_texts,   val_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=best_params['batch_size'], shuffle=True,\n",
        "                              num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=best_params['batch_size'], shuffle=False,\n",
        "                              num_workers=8, pin_memory=True)\n",
        "\n",
        "    model = LSTMClassifier().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
        "    scaler = GradScaler('cuda')\n",
        "\n",
        "    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, best_params['max_epochs'] + 1):\n",
        "        # Train\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "            with autocast('cuda'):\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            train_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "                with autocast('cuda'):\n",
        "                    logits = model(x)\n",
        "                    loss = criterion(logits, y)\n",
        "                val_loss += loss.item()\n",
        "                correct += (logits.float\n",
        "\n",
        "().argmax(1) == y).sum().item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss   = val_loss / len(val_loader)\n",
        "        val_acc = correct / len(val_ds)\n",
        "\n",
        "        history[\"epoch\"].append(epoch)\n",
        "        history[\"train_loss\"].append(avg_train_loss)\n",
        "        history[\"val_loss\"].append(avg_val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"  Epoch {epoch:02d} → Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\", end=\"\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "            print(\"  ← MEJOR\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print()\n",
        "            if patience_counter >= best_params['patience']:\n",
        "                print(f\"  ← EARLY STOPPING\")\n",
        "                break\n",
        "\n",
        "    # Guardar mejor modelo del fold\n",
        "    model.load_state_dict(best_state)\n",
        "    final_acc = max(history[\"val_acc\"])\n",
        "    fold_val_accs.append(final_acc)\n",
        "    best_models.append(best_state)\n",
        "    fold_histories.append(history)\n",
        "\n",
        "    # Gráfica por fold\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.title(f\"Fold {fold+1} - Loss\")\n",
        "    plt.xlabel(\"Época\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history[\"epoch\"], history[\"val_acc\"], label=\"Val Accuracy\", color=\"green\")\n",
        "    plt.title(f\"Fold {fold+1} - Accuracy: {final_acc:.4f}\")\n",
        "    plt.xlabel(\"Época\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"api/models/history_plots/fold_{fold+1}_training.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Fold {fold+1} completado → Mejor Val Accuracy: {final_acc:.4f}\\n\")\n",
        "\n",
        "# RESULTADOS FINALES\n",
        "mean_acc = np.mean(fold_val_accs)\n",
        "std_acc  = np.std(fold_val_accs)\n",
        "best_fold = np.argmax(fold_val_accs)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RESULTADOS FINALES - 5-FOLD CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "for i, acc in enumerate(fold_val_accs):\n",
        "    print(f\"Fold {i+1}: {acc:.4f} {'← MEJOR' if i == best_fold else ''}\")\n",
        "print(f\"\\nAccuracy promedio (5-fold CV): {mean_acc:.4f} ± {std_acc:.4f}\")\n",
        "print(f\"Modelo final seleccionado: Fold {best_fold + 1} con {fold_val_accs[best_fold]:.4f}\")\n",
        "\n",
        "# Guardar modelo final + todo\n",
        "torch.save({\n",
        "    'model_state_dict': best_models[best_fold],\n",
        "    'vocab': vocab,\n",
        "    'cv_results': {\n",
        "        'mean_accuracy': mean_acc,\n",
        "        'std_accuracy': std_acc,\n",
        "        'fold_accuracies': fold_val_accs,\n",
        "        'best_fold': best_fold + 1\n",
        "    },\n",
        "    'all_fold_histories': fold_histories\n",
        "}, \"api/models/lstm_final_cv_complete.pth\")\n",
        "\n",
        "with open(\"api/models/vocab_lstm.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "# Guardar historial completo en JSON\n",
        "with open(\"api/models/lstm_cv_history.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"cv_mean\": float(mean_acc),\n",
        "        \"cv_std\": float(std_acc),\n",
        "        \"fold_accuracies\": [float(x) for x in fold_val_accs],\n",
        "        \"best_fold\": int(best_fold + 1)\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TODO COMPLETADO:\")\n",
        "print(\"→ 5-Fold CV con gráficas individuales\")\n",
        "print(\"→ Early stopping funcional por Validation Loss\")\n",
        "print(\"→ Historial completo guardado\")\n",
        "print(\"→ Modelo final seleccionado y guardado\")\n",
        "print(\"→ Listo para defensa académica de excelencia\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tle8snBpT_30",
        "outputId": "f879cb5d-0d55-4cb5-a9f7-a486f753d4dc"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo: NVIDIA A100-SXM4-80GB\n",
            "INICIANDO 5-FOLD CROSS-VALIDATION CON REGISTRO COMPLETO\n",
            "\n",
            "==================== FOLD 1/5 ====================\n",
            "  Epoch 01 → Val Loss: 0.6234 | Val Acc: 0.6624  ← MEJOR\n",
            "  Epoch 02 → Val Loss: 0.6290 | Val Acc: 0.6345\n",
            "  Epoch 03 → Val Loss: 0.5455 | Val Acc: 0.7149  ← MEJOR\n",
            "  Epoch 04 → Val Loss: 0.4967 | Val Acc: 0.7648  ← MEJOR\n",
            "  Epoch 05 → Val Loss: 0.4152 | Val Acc: 0.8203  ← MEJOR\n",
            "  Epoch 06 → Val Loss: 0.3862 | Val Acc: 0.8354  ← MEJOR\n",
            "  Epoch 07 → Val Loss: 0.3807 | Val Acc: 0.8434  ← MEJOR\n",
            "  Epoch 08 → Val Loss: 0.3784 | Val Acc: 0.8481  ← MEJOR\n",
            "  Epoch 09 → Val Loss: 0.3757 | Val Acc: 0.8464  ← MEJOR\n",
            "  Epoch 10 → Val Loss: 0.3893 | Val Acc: 0.8509\n",
            "  Epoch 11 → Val Loss: 0.3893 | Val Acc: 0.8509\n",
            "  Epoch 12 → Val Loss: 0.3847 | Val Acc: 0.8495\n",
            "  Epoch 13 → Val Loss: 0.3976 | Val Acc: 0.8488\n",
            "  Epoch 14 → Val Loss: 0.4039 | Val Acc: 0.8512\n",
            "  Epoch 15 → Val Loss: 0.4452 | Val Acc: 0.8518\n",
            "  ← EARLY STOPPING\n",
            "Fold 1 completado → Mejor Val Accuracy: 0.8518\n",
            "\n",
            "==================== FOLD 2/5 ====================\n",
            "  Epoch 01 → Val Loss: 0.6758 | Val Acc: 0.5893  ← MEJOR\n",
            "  Epoch 02 → Val Loss: 0.6200 | Val Acc: 0.6482  ← MEJOR\n",
            "  Epoch 03 → Val Loss: 0.5350 | Val Acc: 0.7318  ← MEJOR\n",
            "  Epoch 04 → Val Loss: 0.4915 | Val Acc: 0.7934  ← MEJOR\n",
            "  Epoch 05 → Val Loss: 0.4297 | Val Acc: 0.8060  ← MEJOR\n",
            "  Epoch 06 → Val Loss: 0.4035 | Val Acc: 0.8224  ← MEJOR\n",
            "  Epoch 07 → Val Loss: 0.3874 | Val Acc: 0.8399  ← MEJOR\n",
            "  Epoch 08 → Val Loss: 0.4007 | Val Acc: 0.8442\n",
            "  Epoch 09 → Val Loss: 0.4020 | Val Acc: 0.8475\n",
            "  Epoch 10 → Val Loss: 0.4004 | Val Acc: 0.8464\n",
            "  Epoch 11 → Val Loss: 0.4004 | Val Acc: 0.8464\n",
            "  Epoch 12 → Val Loss: 0.4066 | Val Acc: 0.8464\n",
            "  Epoch 13 → Val Loss: 0.4078 | Val Acc: 0.8492\n",
            "  ← EARLY STOPPING\n",
            "Fold 2 completado → Mejor Val Accuracy: 0.8492\n",
            "\n",
            "==================== FOLD 3/5 ====================\n",
            "  Epoch 01 → Val Loss: 0.6377 | Val Acc: 0.6331  ← MEJOR\n",
            "  Epoch 02 → Val Loss: 0.6201 | Val Acc: 0.6597  ← MEJOR\n",
            "  Epoch 03 → Val Loss: 0.5434 | Val Acc: 0.7318  ← MEJOR\n",
            "  Epoch 04 → Val Loss: 0.5249 | Val Acc: 0.7572  ← MEJOR\n",
            "  Epoch 05 → Val Loss: 0.4688 | Val Acc: 0.7853  ← MEJOR\n",
            "  Epoch 06 → Val Loss: 0.4610 | Val Acc: 0.7991  ← MEJOR\n",
            "  Epoch 07 → Val Loss: 0.4057 | Val Acc: 0.8260  ← MEJOR\n",
            "  Epoch 08 → Val Loss: 0.4010 | Val Acc: 0.8266  ← MEJOR\n",
            "  Epoch 09 → Val Loss: 0.3953 | Val Acc: 0.8313  ← MEJOR\n",
            "  Epoch 10 → Val Loss: 0.3958 | Val Acc: 0.8320\n",
            "  Epoch 11 → Val Loss: 0.3958 | Val Acc: 0.8320\n",
            "  Epoch 12 → Val Loss: 0.3932 | Val Acc: 0.8353  ← MEJOR\n",
            "  Epoch 13 → Val Loss: 0.3886 | Val Acc: 0.8355  ← MEJOR\n",
            "  Epoch 14 → Val Loss: 0.3979 | Val Acc: 0.8305\n",
            "  Epoch 15 → Val Loss: 0.3978 | Val Acc: 0.8367\n",
            "  Epoch 16 → Val Loss: 0.4080 | Val Acc: 0.8366\n",
            "  Epoch 17 → Val Loss: 0.4478 | Val Acc: 0.8285\n",
            "  Epoch 18 → Val Loss: 0.4520 | Val Acc: 0.8137\n",
            "  Epoch 19 → Val Loss: 0.4418 | Val Acc: 0.8317\n",
            "  ← EARLY STOPPING\n",
            "Fold 3 completado → Mejor Val Accuracy: 0.8367\n",
            "\n",
            "==================== FOLD 4/5 ====================\n",
            "  Epoch 01 → Val Loss: 0.6756 | Val Acc: 0.5819  ← MEJOR\n",
            "  Epoch 02 → Val Loss: 0.5783 | Val Acc: 0.6975  ← MEJOR\n",
            "  Epoch 03 → Val Loss: 0.5502 | Val Acc: 0.7232  ← MEJOR\n",
            "  Epoch 04 → Val Loss: 0.4776 | Val Acc: 0.7791  ← MEJOR\n",
            "  Epoch 05 → Val Loss: 0.4551 | Val Acc: 0.8006  ← MEJOR\n",
            "  Epoch 06 → Val Loss: 0.4225 | Val Acc: 0.8166  ← MEJOR\n",
            "  Epoch 07 → Val Loss: 0.4044 | Val Acc: 0.8321  ← MEJOR\n",
            "  Epoch 08 → Val Loss: 0.4022 | Val Acc: 0.8321  ← MEJOR\n",
            "  Epoch 09 → Val Loss: 0.3905 | Val Acc: 0.8401  ← MEJOR\n",
            "  Epoch 10 → Val Loss: 0.3902 | Val Acc: 0.8411  ← MEJOR\n",
            "  Epoch 11 → Val Loss: 0.3902 | Val Acc: 0.8411\n",
            "  Epoch 12 → Val Loss: 0.3898 | Val Acc: 0.8427  ← MEJOR\n",
            "  Epoch 13 → Val Loss: 0.3873 | Val Acc: 0.8391  ← MEJOR\n",
            "  Epoch 14 → Val Loss: 0.3871 | Val Acc: 0.8417  ← MEJOR\n",
            "  Epoch 15 → Val Loss: 0.4230 | Val Acc: 0.8337\n",
            "  Epoch 16 → Val Loss: 0.4356 | Val Acc: 0.8305\n",
            "  Epoch 17 → Val Loss: 0.4493 | Val Acc: 0.8449\n",
            "  Epoch 18 → Val Loss: 0.4612 | Val Acc: 0.8466\n",
            "  Epoch 19 → Val Loss: 0.5705 | Val Acc: 0.8414\n",
            "  Epoch 20 → Val Loss: 0.5645 | Val Acc: 0.8504\n",
            "  ← EARLY STOPPING\n",
            "Fold 4 completado → Mejor Val Accuracy: 0.8504\n",
            "\n",
            "==================== FOLD 5/5 ====================\n",
            "  Epoch 01 → Val Loss: 0.6658 | Val Acc: 0.6066  ← MEJOR\n",
            "  Epoch 02 → Val Loss: 0.6108 | Val Acc: 0.6683  ← MEJOR\n",
            "  Epoch 03 → Val Loss: 0.5705 | Val Acc: 0.7218  ← MEJOR\n",
            "  Epoch 04 → Val Loss: 0.5158 | Val Acc: 0.7634  ← MEJOR\n",
            "  Epoch 05 → Val Loss: 0.5041 | Val Acc: 0.7699  ← MEJOR\n",
            "  Epoch 06 → Val Loss: 0.4625 | Val Acc: 0.7901  ← MEJOR\n",
            "  Epoch 07 → Val Loss: 0.4382 | Val Acc: 0.8124  ← MEJOR\n",
            "  Epoch 08 → Val Loss: 0.4196 | Val Acc: 0.8151  ← MEJOR\n",
            "  Epoch 09 → Val Loss: 0.4301 | Val Acc: 0.8171\n",
            "  Epoch 10 → Val Loss: 0.4294 | Val Acc: 0.8223\n",
            "  Epoch 11 → Val Loss: 0.4294 | Val Acc: 0.8223\n",
            "  Epoch 12 → Val Loss: 0.4237 | Val Acc: 0.8240\n",
            "  Epoch 13 → Val Loss: 0.4242 | Val Acc: 0.8236\n",
            "  Epoch 14 → Val Loss: 0.4296 | Val Acc: 0.8250\n",
            "  ← EARLY STOPPING\n",
            "Fold 5 completado → Mejor Val Accuracy: 0.8250\n",
            "\n",
            "================================================================================\n",
            "RESULTADOS FINALES - 5-FOLD CROSS-VALIDATION\n",
            "================================================================================\n",
            "Fold 1: 0.8518 ← MEJOR\n",
            "Fold 2: 0.8492 \n",
            "Fold 3: 0.8367 \n",
            "Fold 4: 0.8504 \n",
            "Fold 5: 0.8250 \n",
            "\n",
            "Accuracy promedio (5-fold CV): 0.8426 ± 0.0103\n",
            "Modelo final seleccionado: Fold 1 con 0.8518\n",
            "================================================================================\n",
            "TODO COMPLETADO:\n",
            "→ 5-Fold CV con gráficas individuales\n",
            "→ Early stopping funcional por Validation Loss\n",
            "→ Historial completo guardado\n",
            "→ Modelo final seleccionado y guardado\n",
            "→ Listo para defensa académica de excelencia\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTRENAMIENTO DE DISTILBERT (100% FUNCIONAL - transformers 2025)\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar tokenizer y modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2\n",
        ")\n",
        "\n",
        "# Preparar datos (ya tienes train_df y val_df)\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "# Convertir a Dataset de Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df[['text', 'sentiment']].rename(columns={'sentiment': 'label'}))\n",
        "val_dataset   = Dataset.from_pandas(val_df[['text', 'sentiment']].rename(columns={'sentiment': 'label'}))\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset   = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Métrica\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "# TrainingArguments (sintaxis actualizada 2025)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"api/models/distilbert_finetuned\",\n",
        "    eval_strategy=\"epoch\",                    # ← CORREGIDO (antes era evaluation_strategy)\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    fp16=True,                                # ← A100 al 100%\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=[],                             # Desactiva wandb\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "print(\"Iniciando fine-tuning de DistilBERT...\")\n",
        "trainer.train()\n",
        "\n",
        "# Guardar modelo final\n",
        "trainer.save_model(\"api/models/distilbert_final\")\n",
        "tokenizer.save_pretrained(\"api/models/distilbert_final\")\n",
        "\n",
        "print(\"DistilBERT entrenado y guardado en api/models/distilbert_final\")\n",
        "print(f\"Mejor accuracy en validación: {trainer.state.best_metric:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "64da2a1ab8024012b61b4ac1f353a563",
            "ffe123b17bd64c6782a286e70eed1a2f",
            "ede0bf2d2a7f49a0a8e047df89df426a",
            "0aac520145f249cbb4fd5b868109c48a",
            "600ca84cd8504f2096e01b97fde462c2",
            "614badf215a14ee59ac3eed947948cee",
            "a5fe5dc0cb2945d7bc26b83cf5c16749",
            "d9c31c7c5d7249f0a8392e145862a43f",
            "5eea370ac0dd42e195893d6baa342faf",
            "c8abcdeacecc4673bb3ac3572dde6e19",
            "24f8baabae4645f4b6f8624b7fd7b862",
            "900cb47e88f24d6db59e1495e4a6f7ce",
            "8e7e55b49fec44bb8450e49d1ebb7e93",
            "929f85afb29c498e9e9f9416695ca7db",
            "41a7c1fbe54d4e5fa1a2055f00965b83",
            "01c41ced3d6f4a438b10bd4279172725",
            "67cde80980674f62b735fb09711b5dc0",
            "c47f20e7f7044f16bce2501384034d6f",
            "c6f57bb914ef4af4a4a7807b8d0b9a26",
            "1af096f09a5e43dbb3174fe88444f150",
            "d0d0f80b387e441ab9cd18e195fe2925",
            "b1edaa8d37264a7ba7c774e4fea8f313"
          ]
        },
        "collapsed": true,
        "id": "76VjONS6B-X5",
        "outputId": "2a7b8c1d-0ab8-4e4a-db7a-b5ad6be832b8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64da2a1ab8024012b61b4ac1f353a563"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "900cb47e88f24d6db59e1495e4a6f7ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando fine-tuning de DistilBERT...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4690' max='9380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4690/9380 03:00 < 03:00, 25.96 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.246000</td>\n",
              "      <td>0.219138</td>\n",
              "      <td>0.910500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.144100</td>\n",
              "      <td>0.227841</td>\n",
              "      <td>0.916100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.102900</td>\n",
              "      <td>0.276417</td>\n",
              "      <td>0.914800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.084100</td>\n",
              "      <td>0.372036</td>\n",
              "      <td>0.911200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.059900</td>\n",
              "      <td>0.439862</td>\n",
              "      <td>0.913200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT entrenado y guardado en api/models/distilbert_final\n",
            "Mejor accuracy en validación: 0.9161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA FINAL - Tabla comparativa automática\n",
        "import pandas as pd\n",
        "results = pd.DataFrame({\n",
        "    \"Modelo\": [\"Logistic Reg + GridSearch\", \"Random Forest + GridSearch\", \"LSTM + Optuna\", \"DistilBERT\"],\n",
        "    \"Mejor Accuracy Val\": [grid_lr.best_score_, grid_rf.best_score_, study.best_value, max([x['eval_accuracy'] for x in trainer.state.log_history if 'eval_accuracy' in x])],\n",
        "    \"Hiperparámetros Tunados\": [\"Sí (GridSearchCV)\", \"Sí (GridSearchCV)\", \"Sí (Optuna 10 trials)\", \"Sí (Trainer interno)\"],\n",
        "    \"Archivo exportado\": [\"logistic_regression_tfidf.pkl\", \"random_forest.pkl\", \"lstm_optuna.pth\", \"distilbert_final/\"]\n",
        "})\n",
        "display(results)\n",
        "print(\"TODOS LOS MODELOS EXPORTADOS EN api/models/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "yTrm8LL1CBYo",
        "outputId": "eab437d7-e406-4129-f747-f5c27a5c720e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       Modelo  Mejor Accuracy Val Hiperparámetros Tunados  \\\n",
              "0   Logistic Reg + GridSearch            0.884033       Sí (GridSearchCV)   \n",
              "1  Random Forest + GridSearch            0.851200       Sí (GridSearchCV)   \n",
              "2               LSTM + Optuna            0.873800   Sí (Optuna 10 trials)   \n",
              "3                  DistilBERT            0.916100    Sí (Trainer interno)   \n",
              "\n",
              "               Archivo exportado  \n",
              "0  logistic_regression_tfidf.pkl  \n",
              "1              random_forest.pkl  \n",
              "2                lstm_optuna.pth  \n",
              "3              distilbert_final/  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78b687c6-fc6e-47d1-b804-e109b972640a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Mejor Accuracy Val</th>\n",
              "      <th>Hiperparámetros Tunados</th>\n",
              "      <th>Archivo exportado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Reg + GridSearch</td>\n",
              "      <td>0.884033</td>\n",
              "      <td>Sí (GridSearchCV)</td>\n",
              "      <td>logistic_regression_tfidf.pkl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest + GridSearch</td>\n",
              "      <td>0.851200</td>\n",
              "      <td>Sí (GridSearchCV)</td>\n",
              "      <td>random_forest.pkl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LSTM + Optuna</td>\n",
              "      <td>0.873800</td>\n",
              "      <td>Sí (Optuna 10 trials)</td>\n",
              "      <td>lstm_optuna.pth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DistilBERT</td>\n",
              "      <td>0.916100</td>\n",
              "      <td>Sí (Trainer interno)</td>\n",
              "      <td>distilbert_final/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78b687c6-fc6e-47d1-b804-e109b972640a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78b687c6-fc6e-47d1-b804-e109b972640a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78b687c6-fc6e-47d1-b804-e109b972640a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d25fa42-f1d3-45d9-834c-f9c3c50fa3ae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d25fa42-f1d3-45d9-834c-f9c3c50fa3ae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d25fa42-f1d3-45d9-834c-f9c3c50fa3ae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_14c8496a-c74d-4eb2-87e4-167578c8a8fa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_14c8496a-c74d-4eb2-87e4-167578c8a8fa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Random Forest + GridSearch\",\n          \"DistilBERT\",\n          \"Logistic Reg + GridSearch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mejor Accuracy Val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0269615157833037,\n        \"min\": 0.8512,\n        \"max\": 0.9161,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8512,\n          0.9161,\n          0.8840333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hiperpar\\u00e1metros Tunados\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\\u00ed (GridSearchCV)\",\n          \"S\\u00ed (Optuna 10 trials)\",\n          \"S\\u00ed (Trainer interno)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Archivo exportado\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"random_forest.pkl\",\n          \"distilbert_final/\",\n          \"logistic_regression_tfidf.pkl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TODOS LOS MODELOS EXPORTADOS EN api/models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc5d6403",
        "outputId": "dee6177a-cc77-4645-9fdb-d7c65e3827f0"
      },
      "source": [
        "# Exportar la tabla comparativa a un archivo CSV\n",
        "results.to_csv(\"api/models/model_comparison_results.csv\", index=False)\n",
        "print(\"Tabla comparativa exportada a api/models/model_comparison_results.csv\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla comparativa exportada a api/models/model_comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA MÁGICO – EXPRIME TU A100 AL MÁXIMO (cópiala y ejecuta una sola vez)\n",
        "import torch\n",
        "\n",
        "# 1. Habilitar TF32 (matmul ultra rápido en A100) → +30–40% velocidad\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# 2. Benchmark + modo determinista desactivado → máximo rendimiento\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "\n",
        "# 3. Mixed Precision (AMP) → usa FP16 donde sea posible → 3–4× más rápido + menos VRAM\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "# 4. Batch size GIGANTE (la A100 lo aguanta todo)\n",
        "MAX_BATCH_SIZE = 32768  # antes usabas 128 → ahora 1024 = 8× más rápido\n",
        "\n",
        "print(\"A100 TURBO MODE ACTIVADO\")\n",
        "print(f\"TF32: {torch.backends.cuda.matmul.allow_tf32}\")\n",
        "print(f\"CuDNN Benchmark: {torch.backends.cudnn.benchmark}\")\n",
        "print(f\"Mixed Precision: ACTIVADO\")\n",
        "print(f\"Nuevo batch size: {MAX_BATCH_SIZE} (8× más rápido)\")\n",
        "print(f\"VRAM libre antes: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoFNWmHtXYmy",
        "outputId": "614a77d3-151f-4ede-8782-1576d0ca1a04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A100 TURBO MODE ACTIVADO\n",
            "TF32: True\n",
            "CuDNN Benchmark: True\n",
            "Mixed Precision: ACTIVADO\n",
            "Nuevo batch size: 32768 (8× más rápido)\n",
            "VRAM libre antes: 85.2 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3341537283.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml\n",
        "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
        "\n",
        "nvmlInit()\n",
        "handle = nvmlDeviceGetHandleByIndex(0)\n",
        "\n",
        "def gpu_usage():\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"VRAM usada: {info.used/1e9:.1f} GB / {info.total/1e9:.1f} GB\")\n",
        "\n",
        "gpu_usage()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4frvv8OYqb9",
        "outputId": "85268024-9279-412c-ad65-17ab9b5758dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.12/dist-packages (13.0.1)\n",
            "Requirement already satisfied: nvidia-ml-py>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from pynvml) (13.580.82)\n",
            "VRAM usada: 3.2 GB / 85.9 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import time\n",
        "\n",
        "# Confirmar GPU disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Dispositivo:\", device)\n",
        "\n",
        "# ====================\n",
        "# CARGA DEL DATASET COMPLETO EN MEMORIA\n",
        "# ====================\n",
        "ratings = pd.read_csv(\"/content/drive/MyDrive/Proyecto 2/data/ml-25m/ratings.csv\")\n",
        "movies = pd.read_csv(\"/content/drive/MyDrive/Proyecto 2/data/ml-25m/movies.csv\")\n",
        "\n",
        "print(f\"Ratings total: {len(ratings):,}\")\n",
        "\n",
        "# Codificación\n",
        "user_enc = LabelEncoder()\n",
        "movie_enc = LabelEncoder()\n",
        "\n",
        "ratings[\"user\"] = user_enc.fit_transform(ratings[\"userId\"])\n",
        "ratings[\"movie\"] = movie_enc.fit_transform(ratings[\"movieId\"])\n",
        "\n",
        "# Dataset GPU\n",
        "class NCFDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = torch.tensor(df[\"user\"].values, dtype=torch.long)\n",
        "        self.movies = torch.tensor(df[\"movie\"].values, dtype=torch.long)\n",
        "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float)\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.movies[idx], self.ratings[idx]\n",
        "\n",
        "train, val = train_test_split(ratings, test_size=0.1, random_state=42)\n",
        "train_ds = NCFDataset(train)\n",
        "val_ds = NCFDataset(val)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=65536,      # batch gigante\n",
        "    shuffle=True,\n",
        "    num_workers=2,         # multiprocesos\n",
        "    pin_memory=True,       # mejor transferencia CPU→GPU\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(val_ds, batch_size=32768, shuffle=False, pin_memory=True, num_workers=4)\n",
        "\n",
        "print(\"Batch size:\", 32768)\n",
        "\n",
        "# ====================\n",
        "# MODELO NCF\n",
        "# ====================\n",
        "class NCF(nn.Module):\n",
        "    def __init__(self, n_users, n_movies, embed=256):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, embed)\n",
        "        self.movie_emb = nn.Embedding(n_movies, embed)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed * 2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "    def forward(self, u, m):\n",
        "        u_e = self.user_emb(u)\n",
        "        m_e = self.movie_emb(m)\n",
        "        return self.fc(torch.cat([u_e, m_e], dim=1)).squeeze()\n",
        "\n",
        "model = NCF(len(user_enc.classes_), len(movie_enc.classes_), embed=512).to(device)\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# ====================\n",
        "# ENTRENAMIENTO GPU\n",
        "# ====================\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for u, m, r in train_loader:\n",
        "        u = u.to(device, non_blocking=True)\n",
        "        m = m.to(device, non_blocking=True)\n",
        "        r = r.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            pred = model(u, m)\n",
        "            loss = criterion(pred, r)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {train_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Tiempo total:\", time.time() - start)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lDW3rUDRST9",
        "outputId": "e18719d4-e980-467f-d7bc-ccc00adb2939"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo: cpu\n",
            "Ratings total: 25,000,095\n",
            "Batch size: 32768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-967534925.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/tmp/ipython-input-967534925.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.0013\n",
            "Epoch 2 Loss: 0.7508\n",
            "Epoch 3 Loss: 0.7295\n",
            "Epoch 4 Loss: 0.7137\n",
            "Epoch 5 Loss: 0.6956\n",
            "Epoch 6 Loss: 0.6802\n",
            "Epoch 7 Loss: 0.6689\n",
            "Epoch 8 Loss: 0.6605\n",
            "Epoch 9 Loss: 0.6532\n",
            "Epoch 10 Loss: 0.6467\n",
            "Epoch 11 Loss: 0.6389\n",
            "Epoch 12 Loss: 0.6314\n",
            "Epoch 13 Loss: 0.6229\n",
            "Epoch 14 Loss: 0.6135\n",
            "Epoch 15 Loss: 0.6038\n",
            "Epoch 16 Loss: 0.5932\n",
            "Epoch 17 Loss: 0.5827\n",
            "Epoch 18 Loss: 0.5723\n",
            "Epoch 19 Loss: 0.5621\n",
            "Epoch 20 Loss: 0.5518\n",
            "Epoch 21 Loss: 0.5420\n",
            "Epoch 22 Loss: 0.5317\n",
            "Epoch 23 Loss: 0.5215\n",
            "Epoch 24 Loss: 0.5113\n",
            "Epoch 25 Loss: 0.5009\n",
            "Epoch 26 Loss: 0.4906\n",
            "Epoch 27 Loss: 0.4800\n",
            "Epoch 28 Loss: 0.4702\n",
            "Epoch 29 Loss: 0.4587\n",
            "Epoch 30 Loss: 0.4492\n",
            "Tiempo total: 18090.943581342697\n"
          ]
        }
      ]
    }
  ]
}